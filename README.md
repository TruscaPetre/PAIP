### Goal: AGI - Artificial General Intelligence - day 1

Current systems: Empirical, Alchemy, No clear Explanation of how the system works. We don't understand how current systems work. - Not sustainable. 

Let's think about this problem from first principles. 

## LLM problems - day 2

Classical Machine Learning can be compared to a look-up table. This is limiting the reasoning to the training dataset. 

Current system are not optimizing towards thinking, they are only modeling existing knowledge. 
Giving an answer that a human likes does not solve creativity. 
Learning from your own mistakes allows you to achieve a goal as a human. A language model does not try and fail to solve a problem. It what it learns and tris and fails is to model. 

Key insights into thinking are found in:
- The working memory. 
- Working with abstractions, building abstractions. 
- Asking the right questions.

## LLM problems - day 3
Asking for clarification is a problem for genAI sometimes not asking enough, sometimes asking too much for clarifications. The underlying problem is how the system is treating ambiguity of language. 

Richard Feynman - "I am smart enough to know that I am dumb." 

Hallucinations - Confidently answering wrong.
- Wrong answers are fine because they are better than no answer in solving a problem. 
- SOMETIMES You can iterate on top of the wrong answer to arrive eventually to the correct answer.
	- On difficult complex problems can get stuck, more details and context does not unblock the model, and iterations cannot continue progress.