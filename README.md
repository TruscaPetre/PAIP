### Goal: AGI - Artificial General Intelligence - day 1

Current systems: Empirical, Alchemy, No clear Explanation of how the system works. We don't understand how current systems work. - Not sustainable. 

Let's think about this problem from first principles. 

## LLM problems - day 2

To integrate from the second day.

## LLM problems - day 3
Asking for clarification is a problem for genAI sometimes not asking enough, sometimes asking too much for clarifications. The underlying problem is how the system is treating ambiguity of language. 

Richard Feynman - "I am smart enough to know that I am dumb." 

Hallucinations - Confidently answering wrong.
- Wrong answers are fine because they are better than no answer in solving a problem. 
- SOMETIMES You can iterate on top of the wrong answer to arrive eventually to the correct answer.
	- On difficult complex problems can get stuck, more details and context does not unblock the model, and iterations cannot continue progress.



---

# TODO
- Upload videos
- Push changes on github
- Integrate content from video 2 in the files from github
- Combine day 3 with 2 after integrate 2 from video content